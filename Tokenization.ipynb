{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb5173c",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c0af5",
   "metadata": {},
   "source": [
    "**tokenization using the nlp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "678bfdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ajink\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "# if not downloaded nltk essentials then download below\n",
    "nltk.download('punkt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ea00f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi',\n",
       " 'I',\n",
       " 'am',\n",
       " 'writing',\n",
       " 'this',\n",
       " 's',\n",
       " 'ente',\n",
       " 'nce',\n",
       " 'becuase',\n",
       " 'I',\n",
       " 'want',\n",
       " 'to',\n",
       " 'check',\n",
       " 'how',\n",
       " 'nltk',\n",
       " 'libraries',\n",
       " 'works',\n",
       " '?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sentence = \"Hi I am writing this s ente nce becuase I want to check how nltk libraries works?\"\n",
    "tokens = word_tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7622567f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is sample sentence.',\n",
       " 'which belong to the sample paragraph.',\n",
       " 'we are trying to tokenize into the setence then we wre trying to tokenize it into the words also.',\n",
       " 'for both of that we are using the nltk library.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "para = \"this is sample sentence. which belong to the sample paragraph. we are trying to tokenize into the setence then we wre trying to tokenize it into the words also. for both of that we are using the nltk library.\"\n",
    "sent_tokens = sent_tokenize(para)\n",
    "sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff35c7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', 'is', 'sample', 'sentence', '.'],\n",
       " ['which', 'belong', 'to', 'the', 'sample', 'paragraph', '.'],\n",
       " ['we',\n",
       "  'are',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'tokenize',\n",
       "  'into',\n",
       "  'the',\n",
       "  'setence',\n",
       "  'then',\n",
       "  'we',\n",
       "  'wre',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'tokenize',\n",
       "  'it',\n",
       "  'into',\n",
       "  'the',\n",
       "  'words',\n",
       "  'also',\n",
       "  '.'],\n",
       " ['for',\n",
       "  'both',\n",
       "  'of',\n",
       "  'that',\n",
       "  'we',\n",
       "  'are',\n",
       "  'using',\n",
       "  'the',\n",
       "  'nltk',\n",
       "  'library',\n",
       "  '.']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens = []\n",
    "for sent in sent_tokens:\n",
    "    word_tokens.append(word_tokenize(sent))\n",
    "\n",
    "word_tokens \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c1a79ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['t', 'h', 'i', 's'],\n",
       " ['i', 's'],\n",
       " ['s', 'a', 'm', 'p', 'l', 'e'],\n",
       " ['s', 'e', 'n', 't', 'e', 'n', 'c', 'e'],\n",
       " ['.'],\n",
       " ['w', 'h', 'i', 'c', 'h'],\n",
       " ['b', 'e', 'l', 'o', 'n', 'g'],\n",
       " ['t', 'o'],\n",
       " ['t', 'h', 'e'],\n",
       " ['s', 'a', 'm', 'p', 'l', 'e'],\n",
       " ['p', 'a', 'r', 'a', 'g', 'r', 'a', 'p', 'h'],\n",
       " ['.'],\n",
       " ['w', 'e'],\n",
       " ['a', 'r', 'e'],\n",
       " ['t', 'r', 'y', 'i', 'n', 'g'],\n",
       " ['t', 'o'],\n",
       " ['t', 'o', 'k', 'e', 'n', 'i', 'z', 'e'],\n",
       " ['i', 'n', 't', 'o'],\n",
       " ['t', 'h', 'e'],\n",
       " ['s', 'e', 't', 'e', 'n', 'c', 'e'],\n",
       " ['t', 'h', 'e', 'n'],\n",
       " ['w', 'e'],\n",
       " ['w', 'r', 'e'],\n",
       " ['t', 'r', 'y', 'i', 'n', 'g'],\n",
       " ['t', 'o'],\n",
       " ['t', 'o', 'k', 'e', 'n', 'i', 'z', 'e'],\n",
       " ['i', 't'],\n",
       " ['i', 'n', 't', 'o'],\n",
       " ['t', 'h', 'e'],\n",
       " ['w', 'o', 'r', 'd', 's'],\n",
       " ['a', 'l', 's', 'o'],\n",
       " ['.'],\n",
       " ['f', 'o', 'r'],\n",
       " ['b', 'o', 't', 'h'],\n",
       " ['o', 'f'],\n",
       " ['t', 'h', 'a', 't'],\n",
       " ['w', 'e'],\n",
       " ['a', 'r', 'e'],\n",
       " ['u', 's', 'i', 'n', 'g'],\n",
       " ['t', 'h', 'e'],\n",
       " ['n', 'l', 't', 'k'],\n",
       " ['l', 'i', 'b', 'r', 'a', 'r', 'y'],\n",
       " ['.']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chara  = []\n",
    "for words in word_tokens:\n",
    "    for char in words:\n",
    "        chara.append(list(char))\n",
    "\n",
    "chara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b2f501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
